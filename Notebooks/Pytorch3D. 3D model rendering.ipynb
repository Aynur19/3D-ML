{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing the environment","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport torch\nfrom packaging import version\n\nneed_pytorch3d = False\npytorch3dVersion = '0.6.0'\n\ntry:\n    import pytorch3d as p3d\n    if version.parse(p3d.__version__) < version.parse(pytorch3dVersion):\n        need_pytorch3d = True\nexcept ModuleNotFoundError:\n    need_pytorch3d = True\n\n!curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n!tar xzf 1.10.0.tar.gz\nos.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n!pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-14T16:22:07.011683Z","iopub.execute_input":"2021-11-14T16:22:07.012259Z","iopub.status.idle":"2021-11-14T16:22:22.064720Z","shell.execute_reply.started":"2021-11-14T16:22:07.012218Z","shell.execute_reply":"2021-11-14T16:22:22.063752Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import pytorch3d as p3d \nprint(p3d.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T16:22:46.476773Z","iopub.execute_input":"2021-11-14T16:22:46.477610Z","iopub.status.idle":"2021-11-14T16:22:46.482794Z","shell.execute_reply.started":"2021-11-14T16:22:46.477566Z","shell.execute_reply":"2021-11-14T16:22:46.481944Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\n\n# Util function for loading meshes\nimport pytorch3d.structures as py3d_struct\n\nfrom pytorch3d.io import load_objs_as_meshes, load_obj\nfrom pytorch3d.ops import sample_points_from_meshes\n\n# Data structures and functions for rendering\nfrom pytorch3d.structures import Meshes\nfrom pytorch3d.vis.plotly_vis import AxisArgs, plot_batch_individually, plot_scene\nfrom pytorch3d.vis.texture_vis import texturesuv_image_matplotlib\n\nfrom pytorch3d.renderer import look_at_view_transform, look_at_rotation\nfrom pytorch3d.renderer import OpenGLPerspectiveCameras, FoVPerspectiveCameras, FoVOrthographicCameras\nfrom pytorch3d.renderer import PointLights, DirectionalLights\nfrom pytorch3d.renderer import Materials, RasterizationSettings, PointsRasterizationSettings\nfrom pytorch3d.renderer import MeshRenderer, MeshRasterizer  \nfrom pytorch3d.renderer import SoftPhongShader, HardPhongShader\nfrom pytorch3d.renderer import TexturesUV, TexturesVertex\nfrom pytorch3d.renderer import PointsRenderer, PulsarPointsRenderer, PointsRasterizer\nfrom pytorch3d.renderer import AlphaCompositor, NormWeightedCompositor\n\nsys.path.append(os.path.abspath(''))","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:20:35.233086Z","iopub.execute_input":"2021-11-14T17:20:35.233344Z","iopub.status.idle":"2021-11-14T17:20:35.241096Z","shell.execute_reply.started":"2021-11-14T17:20:35.233314Z","shell.execute_reply":"2021-11-14T17:20:35.240236Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom mpl_toolkits.mplot3d import Axes3D\n%matplotlib inline\n\nfrom PIL import Image\nfrom IPython.display import Image as IPyImage","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:20:39.430985Z","iopub.execute_input":"2021-11-14T17:20:39.431283Z","iopub.status.idle":"2021-11-14T17:20:39.437811Z","shell.execute_reply.started":"2021-11-14T17:20:39.431252Z","shell.execute_reply":"2021-11-14T17:20:39.437059Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"If you have got a CUDA device, you can use GPU mode","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device('cuda:0')\n    torch.cuda.set_device(device)\nelse:\n    device = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:20:43.348769Z","iopub.execute_input":"2021-11-14T17:20:43.349316Z","iopub.status.idle":"2021-11-14T17:20:43.355011Z","shell.execute_reply.started":"2021-11-14T17:20:43.349276Z","shell.execute_reply":"2021-11-14T17:20:43.354152Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"Downloading the 3D Models","metadata":{}},{"cell_type":"code","source":"!wget -P Models3D/Geralt https://raw.githubusercontent.com/Aynur19/3D-ML/main/Models3D/Geralt/Geralt.obj\n!wget -P Models3D/Geralt https://raw.githubusercontent.com/Aynur19/3D-ML/main/Models3D/Geralt/Geralt.mtl","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:20:50.899258Z","iopub.execute_input":"2021-11-14T17:20:50.899561Z","iopub.status.idle":"2021-11-14T17:20:53.163952Z","shell.execute_reply.started":"2021-11-14T17:20:50.899527Z","shell.execute_reply":"2021-11-14T17:20:53.163149Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"modelPath = './Models3D/Geralt/Geralt.obj'","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:20:56.632391Z","iopub.execute_input":"2021-11-14T17:20:56.632927Z","iopub.status.idle":"2021-11-14T17:20:56.638499Z","shell.execute_reply.started":"2021-11-14T17:20:56.632885Z","shell.execute_reply":"2021-11-14T17:20:56.636437Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"# Mesh Rendering","metadata":{}},{"cell_type":"markdown","source":"Loading and preparing a 3D model for rendering","metadata":{}},{"cell_type":"code","source":"def getMesh_Pytorch3D(modelPath: str):\n    mesh = load_objs_as_meshes([modelPath], device=device)\n\n    verts = mesh.verts_packed()\n    N = verts.shape[0]\n    center = verts.mean(0)\n    scale = max((verts - center).abs().max(0)[0])\n    \n    mesh.offset_verts_(-center)\n    mesh.scale_verts_((1.0 / float(scale)));\n\n    verts_rgb = torch.ones_like(verts)[None]\n    faces = mesh.faces_packed()\n    textures = TexturesVertex(verts_features=verts_rgb.to(device))\n\n    mesh = Meshes(\n        verts=[verts.to(device)],   \n        faces=[faces.to(device)], \n        textures=textures\n    )\n    \n    return mesh","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:21:04.397729Z","iopub.execute_input":"2021-11-14T17:21:04.398519Z","iopub.status.idle":"2021-11-14T17:21:04.405434Z","shell.execute_reply.started":"2021-11-14T17:21:04.398472Z","shell.execute_reply":"2021-11-14T17:21:04.404658Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"def getMeshRenders_Pytorch3D(mesh, center=((0, 0, 0),), distance=2.5, elevation=0.0, maxAzimuth=360, rangeAzimuth=2):\n    frames = []\n    \n    raster_settings = RasterizationSettings(\n        image_size=1024, \n        blur_radius=0.0, \n        faces_per_pixel=1, \n    )\n\n    lights = DirectionalLights(device=device)\n    \n    for azimuth in range(0, maxAzimuth, rangeAzimuth):\n        R, T = look_at_view_transform(distance, elevation, azimuth, at=center) \n        cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n\n        renderer = MeshRenderer(rasterizer=MeshRasterizer(cameras=cameras, raster_settings=raster_settings),\n                                shader=SoftPhongShader(device=device, cameras=cameras, lights=lights))\n\n        frames.append(renderer(mesh)[0, ..., :].cpu().numpy())\n\n    return frames;","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:21:05.424376Z","iopub.execute_input":"2021-11-14T17:21:05.424946Z","iopub.status.idle":"2021-11-14T17:21:05.432283Z","shell.execute_reply.started":"2021-11-14T17:21:05.424907Z","shell.execute_reply":"2021-11-14T17:21:05.431411Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"Getting render images from different angles","metadata":{}},{"cell_type":"code","source":"mesh = getMesh_Pytorch3D(modelPath)\nframes = getMeshRenders_Pytorch3D(mesh, center=((0, 0, 0),), distance=2.5, elevation=0.0, rangeAzimuth=4)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:21:14.826856Z","iopub.execute_input":"2021-11-14T17:21:14.827179Z","iopub.status.idle":"2021-11-14T17:21:26.177405Z","shell.execute_reply.started":"2021-11-14T17:21:14.827135Z","shell.execute_reply":"2021-11-14T17:21:26.176630Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"Getting animation and displaying","metadata":{}},{"cell_type":"code","source":"def saveGif(frames, path):\n    imgFrames = [Image.fromarray((image * 255).astype(np.uint8)) for image in frames]\n    meshGif = imgFrames[0]\n    meshGif.save(path, format='GIF', append_images=imgFrames, save_all=True, duration=100, loop=0)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:21:26.179207Z","iopub.execute_input":"2021-11-14T17:21:26.179488Z","iopub.status.idle":"2021-11-14T17:21:26.184707Z","shell.execute_reply.started":"2021-11-14T17:21:26.179430Z","shell.execute_reply":"2021-11-14T17:21:26.183989Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"meshGifPath = f'./Pytorch3D. Mesh Rendering (Geralt).gif'\nsaveGif(frames, meshGifPath)\n\nIPyImage(filename=meshGifPath)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:21:26.186084Z","iopub.execute_input":"2021-11-14T17:21:26.186661Z","iopub.status.idle":"2021-11-14T17:21:28.971546Z","shell.execute_reply.started":"2021-11-14T17:21:26.186617Z","shell.execute_reply":"2021-11-14T17:21:28.970528Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"markdown","source":"# Point Cloud Rendering","metadata":{}},{"cell_type":"code","source":"points = mesh.verts_packed()\nrgb = torch.ones(size=(points.shape[0], 3), device=device)\npoint_cloud = py3d_struct.Pointclouds(points=[points], features=[rgb])","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:22:06.152534Z","iopub.execute_input":"2021-11-14T17:22:06.153163Z","iopub.status.idle":"2021-11-14T17:22:06.162353Z","shell.execute_reply.started":"2021-11-14T17:22:06.153122Z","shell.execute_reply":"2021-11-14T17:22:06.161575Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"def getPointCloudRenders_Pytorch3D(pc, center=((0, 0, 0),), distance=2.5, elevation=0.0, maxAzimuth=360, rangeAzimuth=2):\n    frames = []\n    \n    for azimuth in range(0, maxAzimuth, rangeAzimuth):\n        R, T = look_at_view_transform(distance, elevation, azimuth)\n        cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n\n        raster_settings = PointsRasterizationSettings(image_size=1024, radius = 0.003, points_per_pixel = 10)\n        rasterizer = PointsRasterizer(cameras=cameras, raster_settings=raster_settings)\n        renderer = PointsRenderer(rasterizer=rasterizer, compositor=AlphaCompositor())\n    \n        frames.append(renderer(pc)[0, ..., :].cpu().numpy())\n    return frames;","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:22:06.781503Z","iopub.execute_input":"2021-11-14T17:22:06.782140Z","iopub.status.idle":"2021-11-14T17:22:06.789318Z","shell.execute_reply.started":"2021-11-14T17:22:06.782095Z","shell.execute_reply":"2021-11-14T17:22:06.788527Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"frames = getPointCloudRenders_Pytorch3D(point_cloud, center=((0, 0, 0),), distance=2.5, elevation=0.0, rangeAzimuth=4)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:22:12.303803Z","iopub.execute_input":"2021-11-14T17:22:12.304338Z","iopub.status.idle":"2021-11-14T17:22:18.338077Z","shell.execute_reply.started":"2021-11-14T17:22:12.304298Z","shell.execute_reply":"2021-11-14T17:22:18.337287Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"meshGifPath = f'./Pytorch3D. Point Cloud Rendering (Geralt).gif'\nsaveGif(frames, meshGifPath)\n\nIPyImage(filename=meshGifPath)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:22:18.339689Z","iopub.execute_input":"2021-11-14T17:22:18.339926Z","iopub.status.idle":"2021-11-14T17:22:23.025336Z","shell.execute_reply.started":"2021-11-14T17:22:18.339893Z","shell.execute_reply":"2021-11-14T17:22:23.024558Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"markdown","source":"# Sampled Point Cloud Rendering","metadata":{}},{"cell_type":"code","source":"points = sample_points_from_meshes(mesh, 10000)[0]\nrgb = torch.ones(size=(points.shape[0], 3), device=device)\npoint_cloud = py3d_struct.Pointclouds(points=[points], features=[rgb])","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:22:26.537854Z","iopub.execute_input":"2021-11-14T17:22:26.538112Z","iopub.status.idle":"2021-11-14T17:22:26.546770Z","shell.execute_reply.started":"2021-11-14T17:22:26.538084Z","shell.execute_reply":"2021-11-14T17:22:26.545969Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"frames = getPointCloudRenders_Pytorch3D(point_cloud, center=((0, 0, 0),), distance=2.5, elevation=0.0, rangeAzimuth=4)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:22:29.239305Z","iopub.execute_input":"2021-11-14T17:22:29.239793Z","iopub.status.idle":"2021-11-14T17:22:34.372853Z","shell.execute_reply.started":"2021-11-14T17:22:29.239752Z","shell.execute_reply":"2021-11-14T17:22:34.372026Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"meshGifPath = f'./Pytorch3D. Sampled Point Cloud Rendering (Geralt).gif'\nsaveGif(frames, meshGifPath)\n\nIPyImage(filename=meshGifPath)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:22:34.374473Z","iopub.execute_input":"2021-11-14T17:22:34.374739Z","iopub.status.idle":"2021-11-14T17:22:39.140547Z","shell.execute_reply.started":"2021-11-14T17:22:34.374703Z","shell.execute_reply":"2021-11-14T17:22:39.139476Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}